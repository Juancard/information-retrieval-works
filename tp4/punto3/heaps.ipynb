{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Agrego al path la carpeta modulos\n",
    "sys.path.insert(0, os.path.abspath(\"../../modulos\"))\n",
    "from Collection import Collection\n",
    "from LexAnalyser import LexAnalyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "tenDocs = Collection(\"corpus/100doc/50doc/10doc/\")\n",
    "fiftyDocs = Collection(\"corpus/100doc/50doc/\")\n",
    "oneHundredDocs = Collection(\"corpus/100doc/\")\n",
    "print len(oneHundredDocs.onlyFiles()) + len(fiftyDocs.onlyFiles()) + len(tenDocs.onlyFiles())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"stem\": \"spanish\",\n",
    "    \"term_min_size\": 3,\n",
    "    \"term_max_size\": 23\n",
    "}\n",
    "lexAnalyser = LexAnalyser(config)\n",
    "uniqueTerms = []\n",
    "totalTermsOnEveryTermAppearance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño: 913\n",
      "Primeros 50:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 33, 33, 33, 34]\n"
     ]
    }
   ],
   "source": [
    "countNewTerms = 0\n",
    "totalTermsOnEveryTermAppearance[\"doc_10\"] = []\n",
    "for doc in tenDocs.onlyFiles():\n",
    "    with codecs.open(doc, mode='rt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            terms = lexAnalyser.analyse(line)[\"terms\"]\n",
    "            for t in terms:\n",
    "                if t not in uniqueTerms:\n",
    "                    uniqueTerms.append(t)\n",
    "                    countNewTerms += 1\n",
    "                totalTermsOnEveryTermAppearance[\"doc_10\"].append(countNewTerms)\n",
    "                \n",
    "print u\"Tamaño:\", len(totalTermsOnEveryTermAppearance[\"doc_10\"])\n",
    "print \"Primeros 50: \", totalTermsOnEveryTermAppearance[\"doc_10\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño: 11694\n",
      "Primeros 50:  [1, 1, 2, 2, 2, 3, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 8, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15, 16, 16, 17, 18, 18, 18, 18, 18, 19, 19]\n"
     ]
    }
   ],
   "source": [
    "countNewTerms = 0\n",
    "totalTermsOnEveryTermAppearance[\"doc_50\"] = []\n",
    "for doc in fiftyDocs.onlyFiles():\n",
    "    with codecs.open(doc, mode='rt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            terms = lexAnalyser.analyse(line)[\"terms\"]\n",
    "            for t in terms:\n",
    "                if t not in uniqueTerms:\n",
    "                    uniqueTerms.append(t)\n",
    "                    countNewTerms += 1\n",
    "                totalTermsOnEveryTermAppearance[\"doc_50\"].append(countNewTerms)\n",
    "                \n",
    "print u\"Tamaño:\", len(totalTermsOnEveryTermAppearance[\"doc_50\"])\n",
    "print \"Primeros 50: \", totalTermsOnEveryTermAppearance[\"doc_50\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño: 19318\n",
      "Primeros 50:  [0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "countNewTerms = 0\n",
    "totalTermsOnEveryTermAppearance[\"doc_100\"] = []\n",
    "for doc in oneHundredDocs.onlyFiles():\n",
    "    with codecs.open(doc, mode='rt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            terms = lexAnalyser.analyse(line)[\"terms\"]\n",
    "            for t in terms:\n",
    "                if t not in uniqueTerms:\n",
    "                    uniqueTerms.append(t)\n",
    "                    countNewTerms += 1\n",
    "                totalTermsOnEveryTermAppearance[\"doc_100\"].append(countNewTerms)\n",
    "\n",
    "print u\"Tamaño:\", len(totalTermsOnEveryTermAppearance[\"doc_100\"])\n",
    "print \"Primeros 50: \", totalTermsOnEveryTermAppearance[\"doc_100\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_10 = totalTermsOnEveryTermAppearance[\"doc_10\"]\n",
    "x_10 = [x+1 for x in range(len(y_10))]\n",
    "\n",
    "y_50 = totalTermsOnEveryTermAppearance[\"doc_50\"]\n",
    "x_50 = [x+1 for x in range(len(y_50))]\n",
    "\n",
    "y_100 = totalTermsOnEveryTermAppearance[\"doc_100\"]\n",
    "x_100 = [x+1 for x in range(len(y_100))]\n",
    "\n",
    "fig = plt.Figure(figsize = (4,4), facecolor = 'W', edgecolor = 'W')\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.set_title('Ley de Heaps - Indexacion incremental\\n')\n",
    "ax.set_xlabel('Terminos totales procesados')\n",
    "ax.set_ylabel('Terminos unicos')\n",
    "\n",
    "ax.plot(x_10, y_10,'r', lw=2.0, label=\"10 documentos\")\n",
    "ax.plot(x_50, y_50,'b', lw=2.0, label=\"50 documentos\")\n",
    "ax.plot(x_100, y_100,'y', lw=2.0, label=\"100 documentos\")\n",
    "ax.legend(loc='upper center', shadow=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax.get_figure().savefig('heaps_incremental.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
